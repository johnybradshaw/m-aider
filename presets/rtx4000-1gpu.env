# RTX 4000 Ada Generation - Single GPU (20GB VRAM)
# Best for: 7B-14B coder models, moderate context
# Cost: ~$0.52/hour

TYPE=g2-gpu-rtx4000a1-s
REGION=de-fra-2
IMAGE=linode/ubuntu24.04

# Recommended models for this configuration:
# - Qwen/Qwen2.5-Coder-14B-Instruct-AWQ (recommended)
# - Qwen/Qwen2.5-Coder-7B-Instruct-AWQ
# - meta-llama/CodeLlama-13b-Instruct-hf

MODEL_ID=Qwen/Qwen2.5-Coder-14B-Instruct-AWQ
SERVED_MODEL_NAME=coder

# Optimized vLLM settings for RTX 4000
VLLM_MAX_MODEL_LEN=16384
VLLM_GPU_MEMORY_UTILIZATION=0.90
VLLM_MAX_NUM_SEQS=1
# VLLM_EXTRA_ARGS=--enable-prefix-caching

# Multi-GPU settings (leave unset for single GPU)
# VLLM_TENSOR_PARALLEL_SIZE=1
